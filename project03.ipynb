{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc88f6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Output: I don't have access to live data or the ability to check current stock prices. However, you can easily find the latest stock price of Tesla by checking financial news websites, stock market apps, or platforms like Google Finance or Yahoo Finance.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import TypedDict, Annotated, Literal\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "import operator\n",
    "\n",
    "# Set your OpenAI API key\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "# Sample USA economy data (as of July 2025)\n",
    "usa_economy_docs = [\n",
    "    \"The US economy is projected to expand at a pace of 1.6% year-over-year in 2025, down from 2.8% in 2024. Source: The Conference Board\",\n",
    "    \"US current-account deficit widened to $450.2 billion in Q1 2025. Source: BEA\",\n",
    "    \"Despite much lower tariffs, the US economy is still expected to grow at a slower rate in 2025 compared with the previous two years. Source: Deloitte\",\n",
    "    \"Several key economic predictions for 2025 include weaker US economic growth. Source: S&P Global\",\n",
    "    \"This year began with high expectations but following strong 2.8% year-over-year growth in GDP. Source: NRF\"\n",
    "]\n",
    "\n",
    "# Set up in-memory vectorstore for RAG\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_texts(usa_economy_docs, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# LLM instance\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Define state\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    category: Literal[\"general\", \"usa_economy\", \"live_news\"]\n",
    "    output: str\n",
    "    validation_result: bool\n",
    "    feedback: str\n",
    "    attempts: Annotated[int, operator.add]\n",
    "\n",
    "# Router node: Classify the query\n",
    "def router_node(state: AgentState) -> dict:\n",
    "    classify_prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"Classify the following query into one of these categories:\n",
    "        - general: for general queries not related to USA economy or live news\n",
    "        - usa_economy: if the query is about USA economy or anything related to USA\n",
    "        - live_news: if the query asks for live or current information, news, or real-time data\n",
    "        \n",
    "        Query: {query}\n",
    "        \n",
    "        Output only the category name.\"\"\"\n",
    "    )\n",
    "    chain = classify_prompt | llm\n",
    "    response = chain.invoke({\"query\": state[\"query\"]})\n",
    "    category = response.content.strip().lower()\n",
    "    return {\"category\": category}\n",
    "\n",
    "# General LLM node\n",
    "def general_node(state: AgentState) -> dict:\n",
    "    prompt_template = \"Answer the query: {query}\"\n",
    "    if state.get(\"feedback\"):\n",
    "        prompt_template += \"\\nPrevious attempt failed with feedback: {feedback}. Correct your answer accordingly.\"\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "    chain = prompt | llm\n",
    "    inputs = {\"query\": state[\"query\"]}\n",
    "    if state.get(\"feedback\"):\n",
    "        inputs[\"feedback\"] = state[\"feedback\"]\n",
    "    output = chain.invoke(inputs).content\n",
    "    return {\"output\": output, \"feedback\": \"\"}  # Clear feedback after use\n",
    "\n",
    "# USA Economy RAG node\n",
    "def usa_rag_node(state: AgentState) -> dict:\n",
    "    docs = retriever.invoke(state[\"query\"])\n",
    "    context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "    prompt_template = \"Answer the query using the following context:\\n{context}\\n\\nQuery: {query}\"\n",
    "    if state.get(\"feedback\"):\n",
    "        prompt_template += \"\\nPrevious attempt failed with feedback: {feedback}. Correct your answer accordingly.\"\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "    chain = prompt | llm\n",
    "    inputs = {\"query\": state[\"query\"], \"context\": context}\n",
    "    if state.get(\"feedback\"):\n",
    "        inputs[\"feedback\"] = state[\"feedback\"]\n",
    "    output = chain.invoke(inputs).content\n",
    "    return {\"output\": output, \"feedback\": \"\"}  # Clear feedback after use\n",
    "\n",
    "# Live News tool node (mocked for demo; in real use, integrate a news API)\n",
    "@tool\n",
    "def get_live_news(query: str) -> str:\n",
    "    \"\"\"Fetch live news related to the query.\"\"\"\n",
    "    # Mock implementation; replace with real API call, e.g., using requests to news API\n",
    "    return f\"Live news as of July 2025 for '{query}': [Mock] US stock market is up 2% today. Economy shows signs of recovery.\"\n",
    "\n",
    "live_news_tool = RunnableLambda(get_live_news)\n",
    "\n",
    "def live_news_node(state: AgentState) -> dict:\n",
    "    prompt_template = \"Use the live news tool to answer: {query}\"\n",
    "    if state.get(\"feedback\"):\n",
    "        prompt_template += \"\\nPrevious attempt failed with feedback: {feedback}. Correct your answer accordingly.\"\n",
    "    # For simplicity, directly call the tool; in full agent, can use langchain agent\n",
    "    news = live_news_tool.invoke(state[\"query\"])\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "    chain = prompt | llm\n",
    "    inputs = {\"query\": state[\"query\"]}\n",
    "    if state.get(\"feedback\"):\n",
    "        inputs[\"feedback\"] = state[\"feedback\"]\n",
    "    # Incorporate news into the prompt actually\n",
    "    full_prompt = prompt_template + \"\\nLive news data: {news}\"\n",
    "    full_prompt = ChatPromptTemplate.from_template(full_prompt)\n",
    "    chain = full_prompt | llm\n",
    "    inputs[\"news\"] = news\n",
    "    output = chain.invoke(inputs).content\n",
    "    return {\"output\": output, \"feedback\": \"\"}  # Clear feedback after use\n",
    "\n",
    "# Validation node\n",
    "def validation_node(state: AgentState) -> dict:\n",
    "    validate_prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"Validate if the following output correctly and completely answers the query.\n",
    "        Query: {query}\n",
    "        Output: {output}\n",
    "        \n",
    "        Respond with 'Yes' if valid, 'No' if not. If No, provide feedback on why it's invalid and how to correct it.\"\"\"\n",
    "    )\n",
    "    chain = validate_prompt | llm\n",
    "    response = chain.invoke({\"query\": state[\"query\"], \"output\": state[\"output\"]}).content\n",
    "    if \"Yes\" in response:\n",
    "        return {\"validation_result\": True}\n",
    "    else:\n",
    "        # Extract feedback (assuming the response includes explanation after 'No')\n",
    "        feedback = response.split(\"No\")[1].strip() if \"No\" in response else \"Invalid output.\"\n",
    "        attempts = state.get(\"attempts\", 0) + 1\n",
    "        return {\"validation_result\": False, \"feedback\": feedback, \"attempts\": attempts}\n",
    "\n",
    "# Conditional routing after router\n",
    "def route_after_router(state: AgentState) -> str:\n",
    "    category = state[\"category\"]\n",
    "    print(f\"Category: {category}\")\n",
    "    if category == \"usa_economy\":\n",
    "        return \"usa_rag\"\n",
    "    elif category == \"live_news\":\n",
    "        return \"live_news\"\n",
    "    else:\n",
    "        return \"general\"\n",
    "\n",
    "# Conditional after validation\n",
    "def decide_after_validation(state: AgentState) -> str:\n",
    "    if state[\"validation_result\"] or state.get(\"attempts\", 0) > 3:\n",
    "        return \"end\"\n",
    "    else:\n",
    "        category = state[\"category\"]\n",
    "        if category == \"usa_economy\":\n",
    "            return \"usa_rag\"\n",
    "        elif category == \"live_news\":\n",
    "            return \"live_news\"\n",
    "        else:\n",
    "            return \"general\"\n",
    "\n",
    "# Build the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"router\", router_node)\n",
    "workflow.add_node(\"general\", general_node)\n",
    "workflow.add_node(\"usa_rag\", usa_rag_node)\n",
    "workflow.add_node(\"live_news\", live_news_node)\n",
    "workflow.add_node(\"validate\", validation_node)\n",
    "\n",
    "workflow.set_entry_point(\"router\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"router\",\n",
    "    route_after_router,\n",
    "    {\"general\": \"general\", \"usa_rag\": \"usa_rag\", \"live_news\": \"live_news\"}\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"general\", \"validate\")\n",
    "workflow.add_edge(\"usa_rag\", \"validate\")\n",
    "workflow.add_edge(\"live_news\", \"validate\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"validate\",\n",
    "    decide_after_validation,\n",
    "    {\"general\": \"general\", \"usa_rag\": \"usa_rag\", \"live_news\": \"live_news\", \"end\": END}\n",
    ")\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    initial_state = {\"query\": \"What is stock price of tesla\", \"attempts\": 0, \"validation_result\": False, \"feedback\": \"\"}\n",
    "    result = app.invoke(initial_state)\n",
    "    print(\"Final Output:\", result[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acb161b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8352ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
